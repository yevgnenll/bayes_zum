# chapter 1


## [이전 목차 페이지로 이동](./README.md)

베이지안 통계에 깔린 기본 개념이 베이즈 이론이다.

조건부 확률 -> 베이즈 이론 -> 베이지안 통계 순으로 넘어간다


## 1. 조건부 확률

특정 조건이 주어졌을때 또다른 조건이 성립할 확률

p(A|B): B라는 조건이 주어졌을때 A라는 조건이 성립할 확률

## 2. 결합 확률(and 조건)

p(A and B) = p(A) * p(B): A, B 모두 참일 확률 

- 단, A, B의 조건은 독립적이어야 한다.


그럼 A, B가 독립적이지 않은 확률

p(A and B) = p(A) * p(B|A)


##### example) 
A = 어제 비가 온 확률

B = 오늘 비가 올 확률

- p(A and b) = p(A) * p(B|A)

## 3. 쿠키

- 1번 접시: 바닐라쿠키 30개, 초코쿠키 10개
- 2번 접시: 바닐라쿠키 20개, 초코쿠키 20개

무심코 쿠키를 꺼냈을때 바닐라 쿠키이고, 1번 집시일 확률

- p(Bowl1 | Vanila)

그런데 1번 접시에서 바닐라 쿠키를 꺼낼 확률 p(vanila | bowl1) = 3/4


결론: p(A|B) !== p(B|A)

베이즈 이론: 하지만 둘 중 하나를 알면 다른 한가지를 구할 수 있다


------------

### 이론의 교환법칙 성립

1. p(A and B) === p(B and A)
2. p(A and B) = p(A)p(B | A)
    - A, B가 무엇인지 언급되지 않았기 때문에
3. p(A)p(B | A) === p(B)p(A | B) 성립
4. p(B)p(A | B) === p(A)p(B | A) 성립 -> 하나로 다른 하나를 찾는 공식

따라서 **p(A|B) = p(A)p(B|A) / p(B)**


-----------

p(Bowl1 | Vanila) == p(B1 | V) 를 구해보자

V = vanila 쿠키 === 5/8
B1 = 1번 접시를 선택할 확률 === 1/2

p(B1 | V): 바닐라 쿠키를 꺼냇는데 그게 1번 접시일 확률

주어진 식: p(vanila | bowl1) = 3/4

```
p(V)p(B1 | V) === p(B1)p(V | B1)
``` 

식이 성립하므로
```
p(B1 | V) = 8/5 * 1/2 * 3/4
return 0.6
```

#### p(A and B) === p(A)p(B | A) === p(B)p(A | B)



## 5. 통시적 해석

무언가가 시간에 따라 일어나는 경우!!

가설(H)에 대한 확률이 시간에 따라 새로운 데이터(D)를 접하면서 달라짐

즉, 데이터는 시간에 의존하는 것이고, 가설은 그 데이터의 영향을 받는다


```
p(H|D) = p(H) p(D|H) / p(D)
```

- p(H)  : 데이터를 보기 전 확률 **사전 확률**
- p(H|D): 계산하고자 하는 데이터를 확인한 이후의 가설확률 **사후 확률**
- p(D|H): 데이터가 가설에 포함될 확률 **우도(가능도)**
- p(D)  : 어떤 가설에든 포함되는 데이터의 비율 **한정 상수**


#### 우도: 만약 쿠키가 어느 그릇에서 나왔는지 안다면, 바닐라 쿠키는 세보면 된다.

#### 한정 상수

정의하기 까다롭다. 다음 경우를 단순화 하여 정의함

- 상호 배제: 집합 중 하나의 가설만 참인경우
- 전체 포괄: 다른 가능성이 전혀 없는 경우. 단 하나의 가설이라도 참인경우

쿠키의 경우는 [전체 확률 법칙](http://www.ktword.co.kr/abbr_view.php?nav=2&id=589&m_temp1=4396)을 사용해 구할 수 있다.

```
p(D) = p(B1)p(D|B1) + p(B2)p(D | B2)
p(D) = 1/2 * 3/4 + 1/2 * 2/1 = 5/8 = 0.625
```

> 전체 확률 법칙: 사건의 원인을 여러가지로 나눈다
> 각 원인에 대한 조건부 확률 p(D|B1) 과 원인의 확률 p(B1)의 곱에 의한
> 가중 합으로 구할 수 있음(공차수열 합)


## 6. M & M 문제

- 1994: 갈색(30%), 노랑(20%), 빨강(20%), 녹색(10%), 주황(10%), 황갈(10%)
- 1996: 파랑(24%), 녹색(20%), 주황(16%), 노랑(14%), 빨강(13%), 갈색(13%)

1994 m&m, 1996 m&m에서 각각 하나씩 뽑아 한 알은 노랑색, 한 알은 녹색일때

노랑 초콜렛이 1994년도 m&m일 확률은??

|   | 사전확률 | 우도 |   |  사후확률  |
|   | p(H)  | p(D|H)   | p(H) p(D|H)  | p(H|D)  |
|---|---|---|---|---|
|A | 1/2  | 20 * 20 | 200 | 20/27  |
|B | 1/2  | 10 * 14 |  70 | 7/27  |

- p(A) = p(B) = 1/2
- 1994) 노랑 1/5, 1996) 녹색 1/5
- 세번째 열을 한정상수 p(H) p(D|H) === p(D) p(H|D)
- 노랑이 1994일 확률과 노랑이 1996인 확률을 더하면 한정산수
- 결과 200/270 = 0.740740741



## 7. 몬티 홀 문제

(앞서 학습한 M & M의 테이블을 사용해야 할듯)


문제

사회자 = 몬티
1. A, B, C 3개의 문이 있고 그 중 한곳에 비싼 자동차, 나머지엔 저가 상품이 있다.
2. 참여자는 3개의 문중 하나를 선택한다.
3. 참여자가 A를 선택했다.
3. 사회자는 비싼 자동차가 없는 문 B, C 하나를 열어 긴장감을 높힌다
4. 사회자가 참여자에게 선택을 바꿀것인지 묻는다

이때 선택을 '고수하면' 1/3이고, '변경하면' 2/3 이다

이 문제를 베이즈 이론을 적용해 실제로 정확한 답이 무엇인지 확정하자


가설: 몬티는 문 B를 선택했고, 거기엔 자동차가 없다.

A, B, C는 자동차가 문 A, 문 B, 문 C 뒤에 있다


|   | 사전확률 | 우도 |   |  사후확률  |
|   | p(H)  | p(D|H)   | p(H) p(D|H)  | p(H|D)  |
|---|---|---|---|---|
| A  | 1/3 | 1/2 | 1/6   | 1/3   |
| B  | 1/3 | 0   | 0  |  0 |
| C  | 1/3 | 1   | 1/3  | 2/3  |

**우도를 찾아보자**

1. 차가 A뒤에 있다면 몬티는 B, C를 열것이다. 몬티가 B를 선택할 확률은 1/2, A에 차가 있으므로, B에 차가 없을 확률은 1
2. 차가 B 뒤에 있다면, 몬티는 C를 열어야 하므로 B를 열 확률은 0이다.
3. 차가 문 C 뒤에 있다면 몬티는 1의 확률로 문 B를 열것이고, 1의 확률로 차가 없다.

p(D) 한정 상수 - 3번째 열의 합: 1/2 












